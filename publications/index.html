<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Publications | Danny Xie </title> <meta name="author" content="Danny Xie"> <meta name="description" content="An overview of my research publications."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%94%AD&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://dnnxl.github.io/publications/"> <script src="/assets/js/theme.js?3fbff01f8940c3d07160da7a6ebc2b99"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <script src="/assets/js/particles.js"></script> <script src="/assets/js/particle-call-function.js"></script> <div id="particles-js"></div> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Danny</span> Xie </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/articles/">Articles </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">News </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/volunteering/">Volunteering </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description">An overview of my research publications.</p> </header> <article> <p>You can browse my work by category below (listed newest to oldest). For the most current list of citations and papers, check out my <a href="https://scholar.google.com/citations?user=vipkAKEAAAAJ&amp;hl=en&amp;authuser=3" rel="external nofollow noopener" target="_blank">Google Scholar</a> or <a href="https://www.semanticscholar.org/author/Danny-Xie-Li/2278092358" rel="external nofollow noopener" target="_blank">Semantic Scholar</a>.</p> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#800000"> <a href="https://cvpr.thecvf.com/" rel="external nofollow noopener" target="_blank">CVPR</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/pinesort.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="pinesort.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="11147940" class="col-sm-8"> <div class="title">PineSORT: A Simple Online Real-Time Tracking Framework for Drone Videos in Agriculture</div> <div class="author"> <em>Danny Xie-Li</em> and Fabian Fallas-Moya </div> <div class="periodical"> <em>In 2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/CVPRW67362.2025.00012" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openaccess.thecvf.com/content/CVPR2025W/LXCV/papers/Xie-Li_PineSORT_A_Simple_Online_Real-time_Tracking_Framework_for_Drone_Videos_CVPRW_2025_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>We introduce PineSORT, a novel Multiple Object Tracking (MOT) system for drone-based agricultural monitoring, specifically tracking pineapples for yield estimation. Our approach tackles key challenges such as repetitive patterns, similar object appearances, low frame rates, and drone motion effects. PineSORT enhances tracking accuracy with motion direction cost, camera motion compensation, a three-stage association strategy, and overlap management. To handle large displacements, we propose an ORB-based camera compensation technique that significantly improves Association Accuracy (AssA). Evaluated via 5-fold cross-validation against BoTSORT and AgriSORT, PineSORT achieves statistically significant gains in Identity-Switch Penalized IDF1 (ISP-IDF1), IDF1, HOTA, and AssA metrics, confirming its effectiveness for tracking low-FPS drone footage and its value for precision agriculture.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">11147940</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xie-Li, Danny and Fallas-Moya, Fabian}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{PineSORT: A Simple Online Real-Time Tracking Framework for Drone Videos in Agriculture}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{65-74}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Accuracy;Costs;Scalability;Cameras;Vectors;Robustness;Yield estimation;Object tracking;Drones;Videos;deep learning;agriculture;video;sort}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/CVPRW67362.2025.00012}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://cvpr.thecvf.com/virtual/2025/35626}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#14a631"> <a href="https://www.bipconference.org/" rel="external nofollow noopener" target="_blank">BIP</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/simple_od_pipeline.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="simple_od_pipeline.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10885396" class="col-sm-8"> <div class="title">Simple Object Detection Framework without Training</div> <div class="author"> <em>Danny Xie-Li</em>, Fabian Fallas-Moya, and Saul Calderon-Ramirez </div> <div class="periodical"> <em>In 2024 IEEE 6th International Conference on BioInspired Processing (BIP)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/BIP63158.2024.10885396" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>This research introduces a simple framework for Object Detection (OD) based on few-shot methods and Visual Foundation Models (VFM). The framework comprises of three core modules: (i) object proposal, (ii) embedding creation, and (iii) object classification. We evaluated six distinct VFMs to generate the object proposals. We compared the performances of four feature extractors to optimize the object representation, including convolutional neural networks and transformer-based models. Furthermore, we investigated four few-shot methods for classifying objects using minimal labeled data. Our framework provides a scalable and cost-effective solution, specifically applied to OD for pineapple localization in the drone imagery of large pineapple fields, where labeled data are scarce and expensive.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10885396</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xie-Li, Danny and Fallas-Moya, Fabian and Calderon-Ramirez, Saul}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2024 IEEE 6th International Conference on BioInspired Processing (BIP)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Simple Object Detection Framework without Training}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-6}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Training;Visualization;Biological system modeling;Object detection;Transformer cores;Feature extraction;Transformers;Proposals;Convolutional neural networks;Drones;visual foundational models;few-shot;object detection}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/BIP63158.2024.10885396}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#00008B"> <a href="https://revistas.tec.ac.cr/index.php/tec_marcha/" rel="external nofollow noopener" target="_blank">TEC</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/stem_ai.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="stem_ai.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="li2023artificial" class="col-sm-8"> <div class="title">Artificial Intelligence in STEM Education: Interactive Hands-on Environment using Open Source Electronic Platforms</div> <div class="author"> Danny Xie Li and Esteban Arias Méndez </div> <div class="periodical"> <em>Tecnologı́a en Marcha</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.18845/tm.v36i6.6759" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dialnet.unirioja.es/descarga/articulo/9046780.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=vipkAKEAAAAJ&amp;citation_for_view=vipkAKEAAAAJ:UeHWp8X0CEIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>This article describes an interactive methodology to teach Artificial Intelligence (AI) through the contructivism philosophy of learning by doing, using, open source electronic platforms, like Arduino, Snap Circuits, Raspberry Pi and Circuit Playground, with an interactive hands-on approach Workshops. These are provided to high school and non-engineering students by (previously trained) engineering students volunteers. The methodology proposed is designed to highlight, in different learning activities, key concepts about Artificial Intelligence (AI). AI abstractes the human intelligence processes through algorithms and computer systems, taking advantage of the amount of data generated nowadays to create innovative, effective, efficient, accurate and at low cost solutions, applied in different fields. The main purpose is to motivate the participants to explode its creativity, improving their innovation skills to provide solutions for XXI century problems, better quality of life, health, among others. A survey will be conducted for the students to find insights about effectiveness of the proposed methodology to better acquire knowledge about AI knowledge. We encourage instructors to use similar interactive hands-on methodologies and to include AI concepts with STEM activities into general education courses. Other concerns of AI, is about the fairness of these algorithms, the inclusion and diversity is a key player in how these systems are built, and it can have consequences as the person perspective when building it The idea of the need for diversity and inclusion of the AI field.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">li2023artificial</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Artificial Intelligence in STEM Education: Interactive Hands-on Environment using Open Source Electronic Platforms}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Danny Xie and M{\'e}ndez, Esteban Arias}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Tecnolog{\'\i}a en Marcha}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{36}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{45--52}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Editorial Tecnol{\'o}gica de Costa Rica}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://dialnet.unirioja.es/servlet/articulo?codigo=9046780}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18845/tm.v36i6.6759}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#14a631"> <a href="https://www.bipconference.org/" rel="external nofollow noopener" target="_blank">BIP</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/multispectral.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="multispectral.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10379335" class="col-sm-8"> <div class="title">Evaluation of the Influence of Multispectral Imaging for Object Detection in Pineapple Crops</div> <div class="author"> Manfred Gonzalez-Hernandez, Fabian Fallas-Moya, Werner Rodriguez-Montero, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Danny Xie-Li, Bryan Roman-Solano, Francini Corrales-Garro, Amir Sadovnik, Hairong Qi' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>In 2023 IEEE 5th International Conference on BioInspired Processing (BIP)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/BIP60195.2023.10379335" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Normally, most studies related to Object Detection focus only on RGB images. However, this research explores the feasibility of utilizing multispectral drone images, incorporating RGB channels with near-infrared, and red-edge channels, to perform Object Detection (OD) using drone images of pineapple crops. There are two main challenges when dealing with multi-spectral images. The first challenge is related to the alignment of the images when dealing with different cameras. Multispectral image alignment corrects for camera position and exposure time differences. We use SIFT and ORB for feature-based exposure matching after initial phase alignment. The second challenge is how to incorporate the extra channels into the RGB images, also known as channel fusion. Here, we studied two fusion techniques: early and late fusion. These techniques offer a comprehensive perspective on the potential of …</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10379335</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gonzalez-Hernandez, Manfred and Fallas-Moya, Fabian and Rodriguez-Montero, Werner and Xie-Li, Danny and Roman-Solano, Bryan and Corrales-Garro, Francini and Sadovnik, Amir and Qi, Hairong}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2023 IEEE 5th International Conference on BioInspired Processing (BIP)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Evaluation of the Influence of Multispectral Imaging for Object Detection in Pineapple Crops}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-6}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Multispectral imaging;Crops;Vegetation mapping;Object detection;Cameras;Indexes;Drones;multispectral;object detection;deep learning}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/BIP60195.2023.10379335}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#FFA500"> <a href="https://2023.ieee-ihtc.org/" rel="external nofollow noopener" target="_blank">IHTC</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/wave-mechanics.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="wave-mechanics.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10508857" class="col-sm-8"> <div class="title">The Women’s Antenna: An experience of community technology construction led by Cabécar women of Costa Rica</div> <div class="author"> Kemly Camacho, Elizabeth Herrera, <em>Danny Xie-Li</em>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Esteban Arias-Méndez' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In 2023 IEEE International Humanitarian Technology Conference (IHTC)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/IHTC58960.2023.10508857" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>The article delves into the experiences of three remarkable women leaders, Mina A., Mina X., and Mina S., within Costa Rica’s Cabécar indigenous community in Alto Pacuare. Referred to as “Mina,” these women play integral roles in decision-making despite their remote locations. Their initiation of the Association of Cabécars Women of Alto Pacuare led to impactful ventures, including the establishment of the “Casa de las Mujeres” (House of Women). Nonetheless, they express apprehensions about the potential internet-induced impact on their age-old culture.Participating in a hackathon organized by Sulá Batsú Cooperative, these leaders proposed a platform aimed at preserving ancestral wisdom. Bolstered by institutional backing, they developed a community network merging natural metaphors to bridge the digital divide.This innovative “walkie talkie” style network seeks to fuse Cabécars women’s traditional …</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10508857</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Camacho, Kemly and Herrera, Elizabeth and Xie-Li, Danny and Arias-Méndez, Esteban}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2023 IEEE International Humanitarian Technology Conference (IHTC)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The Women’s Antenna: An experience of community technology construction led by Cabécar women of Costa Rica}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-7}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Training;Technological innovation;Shape;Decision making;Radio networks;Global communication;Cultural differences;Community networks;Costa Rica;SDGs}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IHTC58960.2023.10508857}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#6714a6"> <a href="https://neurips.cc/Conferences/2020" rel="external nofollow noopener" target="_blank">NeurIPS</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/ml4h_audit.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ml4h_audit.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="pmlr-v136-oala20a" class="col-sm-8"> <div class="title">ML4H Auditing: From Paper to Practice</div> <div class="author"> Luis Oala, Jana Fehr, Luca Gilli, and <span class="more-authors" title="click to view 12 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '12 more authors' ? 'Pradeep Balachandran, Alixandro Werneck Leite, Saul Calderon-Ramirez, Danny Xie Li, Gabriel Nobis, Erick Alejandro Muñoz Alvarado, Giovanna Jaramillo-Gutierrez, Christian Matek, Arun Shroff, Ferath Kherif, Bruno Sanguinetti, Thomas Wiegand' : '12 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">12 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the Machine Learning for Health NeurIPS Workshop</em>, 11 dec 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://proceedings.mlr.press/v136/oala20a/oala20a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://slideslive.com/38941015/ml4h-auditing-from-paper-to-practice" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=vipkAKEAAAAJ&amp;citation_for_view=vipkAKEAAAAJ:0EnyYjriUFMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Healthcare systems are currently adapting to digital technologies, producing large quantities of novel data. Based on these data, machine-learning algorithms have been developed to support practitioners in labor-intensive workflows such as diagnosis, prognosis, triage or treatment of disease. However, their translation into medical practice is often hampered by a lack of careful evaluation in different settings. Efforts have started worldwide to establish guidelines for evaluating machine learning for health (ML4H) tools, highlighting the necessity to evaluate models for bias, interpretability, robustness, and possible failure modes. However, testing and adopting these guidelines in practice remains an open challenge. In this work, we target the paper-to-practice gap by applying an ML4H audit framework proposed by the ITU/WHO Focus Group on Artificial Intelligence for Health (FG-AI4H) to three use cases: diagnostic prediction of diabetic retinopathy, diagnostic prediction of Alzheimer’s disease, and cytomorphologic classification for leukemia diagnostics. The assessment comprises dimensions such as bias, interpretability, and robustness. Our results highlight the importance of fine-grained and caseadapted quality assessment, provide support for incorporating proposed quality assessment considerations of ML4H during the entire development life cycle, and suggest improvements for future ML4H reference evaluation frameworks.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">pmlr-v136-oala20a</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{ML4H Auditing: From Paper to Practice}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Oala, Luis and Fehr, Jana and Gilli, Luca and Balachandran, Pradeep and Leite, Alixandro Werneck and Calderon-Ramirez, Saul and Li, Danny Xie and Nobis, Gabriel and Alvarado, Erick Alejandro Mu\~noz and Jaramillo-Gutierrez, Giovanna and Matek, Christian and Shroff, Arun and Kherif, Ferath and Sanguinetti, Bruno and Wiegand, Thomas}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the Machine Learning for Health NeurIPS Workshop}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{280--317}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Alsentzer, Emily and McDermott, Matthew B. A. and Falck, Fabian and Sarkar, Suproteem K. and Roy, Subhrajit and Hyland, Stephanie L.}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{136}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{11 Dec}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://proceedings.mlr.press/v136/oala20a.html}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Danny Xie. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>