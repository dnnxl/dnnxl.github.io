<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Danny Xie </title> <meta name="author" content="Danny Xie"> <meta name="description" content="Here’s my personal profile, you’re welcome to check it out. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://dnnxl.github.io/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/articles/">Articles </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">News </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/volunteering/">Volunteering </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Danny</span> Xie </h1> <p class="desc"><a href="#">AI Researcher | Adventurous</a></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/profile_photo_casual-480.webp 480w,/assets/img/profile_photo_casual-800.webp 800w,/assets/img/profile_photo_casual-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/profile_photo_casual.jpg?7381f06a47eeed3e21fea2831115a184" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="profile_photo_casual.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>I’m a Master’s student in Computer Science specializing in Artificial Intelligence at the Instituto Tecnológico de Costa Rica. My research is all about putting AI to work in the real world—whether it’s helping biodiversity, boosting agriculture, supporting biomedicine, or making technology more accessible. I’m especially fascinated by diffusion models and foundation models. Lately, I’ve been diving into multiple object tracking, object detection, and pattern recognition, while also experimenting with foundation models and large language models for domain-specific tasks. At the core, my mission is simple: use AI to make a real impact.</p> <p>Outside the lab, you’ll probably find me hiking up a trail, exploring new corners of the world, or behind a camera trying to freeze a fleeting moment. I also enjoy writing and volunteering, fueled by an endless curiosity and a love for learning from every new experience life throws my way.</p> </div> <h2> <a href="/news/" style="color: inherit">News</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Aug 14, 2025</th> <td> Gave a seminar on <em>“A Computer Vision and Deep Learning-Based System for Multi-Object Tracking with Drones in Precision Agriculture”</em> at the <a href="https://cnca.cenat.ac.cr/" rel="external nofollow noopener" target="_blank">Colaboratorio Nacional de Computación Avanzada (CNCA)</a> of the <a href="https://www.cenat.ac.cr/" rel="external nofollow noopener" target="_blank">Centro Nacional de Alta Tecnología (CeNAT)</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 13, 2025</th> <td> Our work has been accepted at the <a href="https://clei.org/" rel="external nofollow noopener" target="_blank">Conferencia Latinoamericana de Informática (CLEI)</a> in Valparaíso, Chile, titled <em>“Squeeze Every Bit of Insight: Leveraging Few-shot Models with a Compact Support Set for Domain Transfer in Object Detection from Pineapple Fields”</em> for oral presentation. </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 23, 2025</th> <td> Delivered a talk for the IEEE Computer Society Student Chapter at the Instituto Tecnológico de Costa Rica, titled <em>“Diffusion Models: Creating What Doesn’t Exist.”</em> </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 31, 2025</th> <td> Our work has been accepted at the <a href="https://cvpr.thecvf.com/" rel="external nofollow noopener" target="_blank">Computer Vision and Pattern Recognition (CVPR)</a> LatinX Workshop in Nashville, United States, titled <em>“PineSORT: A Simple Online Real-time Tracking Framework for Drone Videos in Agriculture”</em>. </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 21, 2025</th> <td> Gave a talk for the IEEE Computer Society Student Chapter at the Instituto Tecnológico de Morelia, México, titled <em>“How Can Computers See? An Introduction to Object Detection.”</em> </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">Selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#6714a6"> <a href="https://neurips.cc/Conferences/2020" rel="external nofollow noopener" target="_blank">NeurIPS</a> </abbr> </div> <div id="pmlr-v136-oala20a" class="col-sm-8"> <div class="title">ML4H Auditing: From Paper to Practice</div> <div class="author"> Luis Oala, Jana Fehr, Luca Gilli, and <span class="more-authors" title="click to view 12 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '12 more authors' ? 'Pradeep Balachandran, Alixandro Werneck Leite, Saul Calderon-Ramirez, Danny Xie Li, Gabriel Nobis, Erick Alejandro Muñoz Alvarado, Giovanna Jaramillo-Gutierrez, Christian Matek, Arun Shroff, Ferath Kherif, Bruno Sanguinetti, Thomas Wiegand' : '12 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">12 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the Machine Learning for Health NeurIPS Workshop</em>, 11 dec 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://proceedings.mlr.press/v136/oala20a/oala20a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://slideslive.com/38941015/ml4h-auditing-from-paper-to-practice" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Healthcare systems are currently adapting to digital technologies, producing large quantities of novel data. Based on these data, machine-learning algorithms have been developed to support practitioners in labor-intensive workflows such as diagnosis, prognosis, triage or treatment of disease. However, their translation into medical practice is often hampered by a lack of careful evaluation in different settings. Efforts have started worldwide to establish guidelines for evaluating machine learning for health (ML4H) tools, highlighting the necessity to evaluate models for bias, interpretability, robustness, and possible failure modes. However, testing and adopting these guidelines in practice remains an open challenge. In this work, we target the paper-to-practice gap by applying an ML4H audit framework proposed by the ITU/WHO Focus Group on Artificial Intelligence for Health (FG-AI4H) to three use cases: diagnostic prediction of diabetic retinopathy, diagnostic prediction of Alzheimer’s disease, and cytomorphologic classification for leukemia diagnostics. The assessment comprises dimensions such as bias, interpretability, and robustness. Our results highlight the importance of fine-grained and caseadapted quality assessment, provide support for incorporating proposed quality assessment considerations of ML4H during the entire development life cycle, and suggest improvements for future ML4H reference evaluation frameworks.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">pmlr-v136-oala20a</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{ML4H Auditing: From Paper to Practice}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Oala, Luis and Fehr, Jana and Gilli, Luca and Balachandran, Pradeep and Leite, Alixandro Werneck and Calderon-Ramirez, Saul and Li, Danny Xie and Nobis, Gabriel and Alvarado, Erick Alejandro Mu\~noz and Jaramillo-Gutierrez, Giovanna and Matek, Christian and Shroff, Arun and Kherif, Ferath and Sanguinetti, Bruno and Wiegand, Thomas}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the Machine Learning for Health NeurIPS Workshop}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{280--317}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Alsentzer, Emily and McDermott, Matthew B. A. and Falck, Fabian and Sarkar, Suproteem K. and Roy, Subhrajit and Hyland, Stephanie L.}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{136}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{11 Dec}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://proceedings.mlr.press/v136/oala20a.html}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#00008B"> <a href="https://revistas.tec.ac.cr/index.php/tec_marcha/" rel="external nofollow noopener" target="_blank">TEC</a> </abbr> </div> <div id="li2023artificial" class="col-sm-8"> <div class="title">Artificial Intelligence in STEM Education: Interactive Hands-on Environment using Open Source Electronic Platforms</div> <div class="author"> Danny Xie Li and Esteban Arias Méndez </div> <div class="periodical"> <em>Tecnologı́a en Marcha</em>, 11 dec 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dialnet.unirioja.es/descarga/articulo/9046780.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>This article describes an interactive methodology to teach Artificial Intelligence (AI) through the contructivism philosophy of learning by doing, using, open source electronic platforms, like Arduino, Snap Circuits, Raspberry Pi and Circuit Playground, with an interactive hands-on approach Workshops. These are provided to high school and non-engineering students by (previously trained) engineering students volunteers. The methodology proposed is designed to highlight, in different learning activities, key concepts about Artificial Intelligence (AI). AI abstractes the human intelligence processes through algorithms and computer systems, taking advantage of the amount of data generated nowadays to create innovative, effective, efficient, accurate and at low cost solutions, applied in different fields. The main purpose is to motivate the participants to explode its creativity, improving their innovation skills to provide solutions for XXI century problems, better quality of life, health, among others. A survey will be conducted for the students to find insights about effectiveness of the proposed methodology to better acquire knowledge about AI knowledge. We encourage instructors to use similar interactive hands-on methodologies and to include AI concepts with STEM activities into general education courses. Other concerns of AI, is about the fairness of these algorithms, the inclusion and diversity is a key player in how these systems are built, and it can have consequences as the person perspective when building it The idea of the need for diversity and inclusion of the AI field.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">li2023artificial</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Artificial Intelligence in STEM Education: Interactive Hands-on Environment using Open Source Electronic Platforms}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Danny Xie and M{\'e}ndez, Esteban Arias}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Tecnolog{\'\i}a en Marcha}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{36}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{45--52}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Editorial Tecnol{\'o}gica de Costa Rica}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://dialnet.unirioja.es/servlet/articulo?codigo=9046780}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#14a631"> <a href="https://www.bipconference.org/" rel="external nofollow noopener" target="_blank">BIP</a> </abbr> </div> <div id="10885396" class="col-sm-8"> <div class="title">Simple Object Detection Framework without Training</div> <div class="author"> Danny Xie-Li, Fabian Fallas-Moya, and Saul Calderon-Ramirez </div> <div class="periodical"> <em>In 2024 IEEE 6th International Conference on BioInspired Processing (BIP)</em>, 11 dec 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/BIP63158.2024.10885396" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>This research introduces a simple framework for Object Detection (OD) based on few-shot methods and Visual Foundation Models (VFM). The framework comprises of three core modules: (i) object proposal, (ii) embedding creation, and (iii) object classification. We evaluated six distinct VFMs to generate the object proposals. We compared the performances of four feature extractors to optimize the object representation, including convolutional neural networks and transformer-based models. Furthermore, we investigated four few-shot methods for classifying objects using minimal labeled data. Our framework provides a scalable and cost-effective solution, specifically applied to OD for pineapple localization in the drone imagery of large pineapple fields, where labeled data are scarce and expensive.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10885396</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xie-Li, Danny and Fallas-Moya, Fabian and Calderon-Ramirez, Saul}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2024 IEEE 6th International Conference on BioInspired Processing (BIP)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Simple Object Detection Framework without Training}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-6}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Training;Visualization;Biological system modeling;Object detection;Transformer cores;Feature extraction;Transformers;Proposals;Convolutional neural networks;Drones;visual foundational models;few-shot;object detection}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/BIP63158.2024.10885396}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100"> <a href="https://cvpr.thecvf.com/" rel="external nofollow noopener" target="_blank">CVPR</a> </abbr> </div> <div id="Xie-Li_2025_CVPR" class="col-sm-8"> <div class="title">PineSORT: A Simple Online Real-time Tracking Framework for Drone Videos in Agriculture</div> <div class="author"> Danny Xie-Li and Fabian Fallas-Moya </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</em>, Jun 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openaccess.thecvf.com/content/CVPR2025W/LXCV/html/Xie-Li_PineSORT_A_Simple_Online_Real-time_Tracking_Framework_for_Drone_Videos_CVPRW_2025_paper.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>We introduce PineSORT, a novel Multiple Object Tracking (MOT) system for drone-based agricultural monitoring, specifically tracking pineapples for yield estimation. Our approach tackles key challenges such as repetitive patterns, similar object appearances, low frame rates, and drone motion effects. PineSORT enhances the tracking accuracy with motion direction cost, camera motion compensation, a three-stage association strategy, and overlap management. To handle large displacements, we propose an ORB-based camera compensation technique that significantly improves the Association Accuracy (AssA). Evaluated via 5-fold cross-validation against BoTSORT and AgriSORT, PineSORT achieves statistically significant gains in our Identity-Switch Penalized IDF1 (ISP-IDF1) metric, along with gains in IDF1 (Identity F1 Score), HOTA (Higher Order Tracking Accuracy) and AssA. These results confirm its effectiveness in tracking low-FPS drone footage, making it a valuable tool for precision agriculture.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Xie-Li_2025_CVPR</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xie-Li, Danny and Fallas-Moya, Fabian}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{PineSORT: A Simple Online Real-time Tracking Framework for Drone Videos in Agriculture}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{65-74}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="https://github.com/dnnxl" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://ieeexplore.ieee.org/author/926958762977822/" title="IEEE Xplore" rel="external nofollow noopener" target="_blank"><i class="ai ai-ieee"></i></a> <a href="https://www.linkedin.com/in/dnnxl" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://orcid.org/0000-0003-1878-9460" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://www.researchgate.net/profile/Danny-Xie-Li?ev=hdr_xprf/" title="ResearchGate" rel="external nofollow noopener" target="_blank"><i class="ai ai-researchgate"></i></a> <a href="https://scholar.google.com/citations?user=vipkAKEAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> </div> <div class="contact-note">Feel free to reach out if you’d like to collaborate, connect, or just have a conversation. I’m always open to new ideas, opportunities, and meaningful discussions. </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Danny Xie. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>